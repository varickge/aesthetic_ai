{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2baea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a68d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_utils import *\n",
    "from ResNet import *\n",
    "from ResNet_FC import *\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184209dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea\n",
    "# fit_generator()\n",
    "# gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "# session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "# gpu = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpu[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a776a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:09:23.713271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.713594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.717387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.717693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.718282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.718563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.719550: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-16 20:09:23.720626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.721235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:23.721840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:24.160276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:24.161002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:24.161686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-16 20:09:24.162348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22132 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "# gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b60bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = generate_root_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac32fd",
   "metadata": {},
   "source": [
    "### DataLoader and other nesseccary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04ba3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_exp_decay(epoch, lr):\n",
    "    k = 0.04\n",
    "    return lr * np.exp(-k*epoch)\n",
    "\n",
    "def make_dataset(paths, batch_size):\n",
    "    main_path = f'{root_path}Data/AesthAI/alm/splitted/alm_train/'\n",
    "    def parse_image(filename):\n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [996, 996]) #ToDo: check this, why we will reizezi img if we load alread resized img\n",
    "        return image\n",
    "\n",
    "    def configure_for_performance(ds):\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "        ds = ds.batch(batch_size)\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    labels = [np.load(main_path + '/predictions/mg_cnn_fc/' + name.split('.')[0].split('/')[-1] + '.npy') for name in paths]\n",
    "    filenames_ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    images_ds = filenames_ds.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
    "    ds = configure_for_performance(ds)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd814f3b",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ad2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, weights_path, train_paths, val_paths, batch_size=128, epochs=30, learning_rate=0.03, verbose=0):\n",
    "    data = make_dataset(train_paths, batch_size)\n",
    "    data_val = make_dataset(val_paths, batch_size)\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(weights_path, monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                                                 mode='min')\n",
    "    schedule = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay, verbose=0)\n",
    "    callbacks_list = [checkpoint, schedule]\n",
    "    history = model.fit(data, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=data_val, \n",
    "                        steps_per_epoch=math.ceil(len(train_paths)/32), validation_steps=math.ceil(len(train_paths)/32), \n",
    "                        validation_batch_size=batch_size, callbacks=callbacks_list)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894e5c7",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2f61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = f'{root_path}Data/AesthAI/alm/splitted/alm_train/'\n",
    "paths_bad = []\n",
    "paths_good = []\n",
    "    \n",
    "for i in range(7):\n",
    "    alm_train_bad = open(f'{main_path}data_bad{i+1}.json')\n",
    "    bad_data = json.load(alm_train_bad)\n",
    "    \n",
    "    for data in bad_data:\n",
    "        path_to_img = main_path + f'images/{data[\"label\"]}/{data[\"splitted\"]}_resized_996x996/' + data['name']\n",
    "        paths_bad.append(path_to_img)\n",
    "        \n",
    "alm_train_good = open(f'{main_path}/data_good1.json')\n",
    "good_data = json.load(alm_train_good)\n",
    "for data in good_data:\n",
    "    path_to_img = main_path + f'images/{data[\"label\"]}/{data[\"splitted\"]}_resized_996x996/' + data['name']\n",
    "    paths_good.append(path_to_img)\n",
    "    \n",
    "for i in range(7):\n",
    "    paths_bad[i] = np.squeeze(np.array(paths_bad[i]))\n",
    "paths_good = np.squeeze(np.array(paths_good))\n",
    "   \n",
    "# Generating static validation data\n",
    "paths_bad, paths_bad_val = extract_static_val_data(paths_bad, perc = 0.014) #original - 0.017\n",
    "paths_good, paths_good_val = extract_static_val_data(paths_good, perc = 0.06) #original - 0.11\n",
    "\n",
    "paths_bad = np.array(paths_bad)\n",
    "paths_bad_val = np.array(paths_bad_val)\n",
    "paths_good = np.array(paths_good)\n",
    "paths_good_val = np.array(paths_good_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8842c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = np.concatenate((np.repeat(paths_good, 7), paths_bad))\n",
    "    \n",
    "#shuffling\n",
    "idx = np.random.permutation(len(full_data))\n",
    "full_data = full_data[idx]\n",
    "# full_data = full_data[:5000]  # debug\n",
    "full_data.shape\n",
    "paths_val = np.concatenate((paths_bad_val, paths_good_val ) , axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97b523",
   "metadata": {},
   "source": [
    "### Creating model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0455249",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #64\n",
    "epochs = 20\n",
    "learning_rate = 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a0d8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_model_softmax(input_num=16928):\n",
    "    input_ = Input(shape=(input_num,))\n",
    "    x = Dense(1024, kernel_initializer='he_normal', activation='relu')(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256, kernel_initializer='he_normal', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    pred = Dense(2, activation='softmax')(x)\n",
    "    model = Model(input_,pred)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53cbc7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <ResNet.ResnetBlock object at 0x7f5f1ed0c5b0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <ResNet.ResnetBlock object at 0x7f5f1ed0c5b0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"resnet_fc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " res_net18 (ResNet18)        multiple                  4074504   \n",
      "                                                                 \n",
      " model (Functional)          (None, 2)                 5389058   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,463,562\n",
      "Trainable params: 9,456,522\n",
      "Non-trainable params: 7,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "model_res = ResNet18(num_classes=5000)\n",
    "model_fc = fc_model_softmax(input_num=5000)\n",
    "model = resnet_fc(model_res, model_fc)\n",
    "model.build((None, 996, 996, 3))\n",
    "\n",
    "weights_path = '../models/Resnet/resnet_fc_996_probs/'\n",
    "# model.save_weights(weights_path)\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c069bdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 20:09:49.631520: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-12-16 20:09:50.087587: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-16 20:09:50.089138: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-16 20:09:50.089274: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2022-12-16 20:09:50.090816: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-16 20:09:50.091317: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-12-16 20:09:51.356287: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0931\n",
      "Epoch 1: val_loss improved from inf to 0.19017, saving model to ../models/Resnet/resnet_fc_996_probs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - 4131s 897ms/step - loss: 0.0931 - val_loss: 0.1902 - lr: 0.0090\n",
      "Epoch 2/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0708\n",
      "Epoch 2: val_loss did not improve from 0.19017\n",
      "4597/4597 [==============================] - 4187s 911ms/step - loss: 0.0708 - val_loss: 0.1920 - lr: 0.0086\n",
      "Epoch 3/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0602\n",
      "Epoch 3: val_loss improved from 0.19017 to 0.10538, saving model to ../models/Resnet/resnet_fc_996_probs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - 4126s 898ms/step - loss: 0.0602 - val_loss: 0.1054 - lr: 0.0080\n",
      "Epoch 4/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0514\n",
      "Epoch 4: val_loss did not improve from 0.10538\n",
      "4597/4597 [==============================] - 4012s 873ms/step - loss: 0.0514 - val_loss: 0.1986 - lr: 0.0071\n",
      "Epoch 5/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0473\n",
      "Epoch 5: val_loss did not improve from 0.10538\n",
      "4597/4597 [==============================] - 4195s 913ms/step - loss: 0.0473 - val_loss: 0.1296 - lr: 0.0060\n",
      "Epoch 6/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0439\n",
      "Epoch 6: val_loss did not improve from 0.10538\n",
      "4597/4597 [==============================] - 4219s 918ms/step - loss: 0.0439 - val_loss: 0.2012 - lr: 0.0049\n",
      "Epoch 7/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 7: val_loss improved from 0.10538 to 0.10473, saving model to ../models/Resnet/resnet_fc_996_probs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - 4091s 890ms/step - loss: 0.0403 - val_loss: 0.1047 - lr: 0.0039\n",
      "Epoch 8/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0372\n",
      "Epoch 8: val_loss improved from 0.10473 to 0.07737, saving model to ../models/Resnet/resnet_fc_996_probs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - 4053s 882ms/step - loss: 0.0372 - val_loss: 0.0774 - lr: 0.0029\n",
      "Epoch 9/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0347\n",
      "Epoch 9: val_loss improved from 0.07737 to 0.06634, saving model to ../models/Resnet/resnet_fc_996_probs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - 4178s 909ms/step - loss: 0.0347 - val_loss: 0.0663 - lr: 0.0021\n",
      "Epoch 10/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0322\n",
      "Epoch 10: val_loss improved from 0.06634 to 0.06251, saving model to ../models/Resnet/resnet_fc_996_probs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/Resnet/resnet_fc_996_probs/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4597/4597 [==============================] - 4230s 920ms/step - loss: 0.0322 - val_loss: 0.0625 - lr: 0.0015\n",
      "Epoch 11/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0304\n",
      "Epoch 11: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4088s 889ms/step - loss: 0.0304 - val_loss: 0.2268 - lr: 9.9723e-04\n",
      "Epoch 12/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0281\n",
      "Epoch 12: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4068s 885ms/step - loss: 0.0281 - val_loss: 0.0725 - lr: 6.4225e-04\n",
      "Epoch 13/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 13: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4128s 898ms/step - loss: 0.0268 - val_loss: 0.0900 - lr: 3.9741e-04\n",
      "Epoch 14/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 14: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4186s 911ms/step - loss: 0.0255 - val_loss: 0.2035 - lr: 2.3627e-04\n",
      "Epoch 15/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 15: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 3999s 870ms/step - loss: 0.0252 - val_loss: 0.0768 - lr: 1.3496e-04\n",
      "Epoch 16/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0246\n",
      "Epoch 16: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4130s 899ms/step - loss: 0.0246 - val_loss: 0.0811 - lr: 7.4068e-05\n",
      "Epoch 17/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 17: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4187s 911ms/step - loss: 0.0244 - val_loss: 0.2326 - lr: 3.9055e-05\n",
      "Epoch 18/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0243\n",
      "Epoch 18: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4100s 892ms/step - loss: 0.0243 - val_loss: 0.1566 - lr: 1.9786e-05\n",
      "Epoch 19/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 19: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 3984s 867ms/step - loss: 0.0241 - val_loss: 0.1865 - lr: 9.6309e-06\n",
      "Epoch 20/20\n",
      "4597/4597 [==============================] - ETA: 0s - loss: 0.0243\n",
      "Epoch 20: val_loss did not improve from 0.06251\n",
      "4597/4597 [==============================] - 4183s 910ms/step - loss: 0.0243 - val_loss: 0.1912 - lr: 4.5041e-06\n"
     ]
    }
   ],
   "source": [
    " history = trainer(model, weights_path, full_data, paths_val, batch_size=batch_size, epochs=epochs, learning_rate=learning_rate, \n",
    "                   verbose=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77911ff0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
