{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ff9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import matplotlib.image as img\n",
    "from glob import glob\n",
    "from final_utils import *\n",
    "from MultiGap_FC import *\n",
    "from lime import lime_image\n",
    "from MultiGap_CNN_FC import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd929b",
   "metadata": {},
   "source": [
    "### Creating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51eb6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model_multigap_cnn_fc()\n",
    "# model2 = model_multigap_fc()\n",
    "root_path = generate_root_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ee7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_imgs_path = glob(os.path.join(root_path, 'Data', 'AesthAI', 'benchmark', 'images', 'good', '*'))\n",
    "bad_imgs_path = glob(os.path.join(root_path, 'Data', 'AesthAI', 'benchmark', 'images', 'bad', '*'))\n",
    "paths_bench = good_imgs_path + bad_imgs_path\n",
    "labels_bench = np.concatenate((np.ones(len(good_imgs_path)) ,np.zeros(len(bad_imgs_path))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6501c",
   "metadata": {},
   "source": [
    "### Some useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(labels, predicted):\n",
    "    return np.sum(np.array(labels) == np.argmax(np.array(predicted), axis=1)) / len(labels)\n",
    "\n",
    "def predict(x, model):\n",
    "    try:\n",
    "        pred = model.predict(x, verbose=0)\n",
    "    except:\n",
    "        x = x[None] #changed 02.08 for evaluator visualizing predictions\n",
    "        pred = model.predict(x, verbose=0)\n",
    "\n",
    "    return pred\n",
    "\n",
    "def predict_from_path(model, paths, resize_func=None, size=None, for_all=False, save_results=None, save_to=None, model_CNN=None):\n",
    "    #always requires list of paths\n",
    "    predicted = []\n",
    "    false_pred = []\n",
    "    \n",
    "    for path in paths:\n",
    "        if 'good' in path:\n",
    "            label = 1\n",
    "        elif 'bad' in path:\n",
    "            label = 0\n",
    "\n",
    "        img = read_img(path=path, resize_func=resize_func, size=size, for_all=for_all)\n",
    "        pred_score = predict(img, model)\n",
    "    \n",
    "        if np.argmax(pred_score) != label:\n",
    "            false_pred.append(path)\n",
    "            \n",
    "        predicted.append(pred_score)\n",
    "    \n",
    "    predicted = np.array(predicted)\n",
    "    predicted = np.squeeze(predicted)\n",
    "    \n",
    "#     if save_results:\n",
    "#         np.save(save_to, np.argmax(predicted, axis=-1))\n",
    "        \n",
    "    return predicted, false_pred\n",
    "\n",
    "def read_and_transform_img(url):\n",
    "    img = Image.open(url)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255\n",
    "    img = resize_max(img, size=(996,996))\n",
    "    print(img.shape)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4253b2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9009009009009009\n"
     ]
    }
   ],
   "source": [
    "acc = calc_acc(labels_bench, predicted)\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f721881",
   "metadata": {},
   "source": [
    "### Saparating false predicted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd4787bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted, false_pred = predict_from_path(model1, paths_bench, resize_func=resize_max, size=(996, 996))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e84f4a",
   "metadata": {},
   "source": [
    "### Explanation for false predictions with LIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6864cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27217d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # index of false predicted image which will be explained\n",
    "\n",
    "images = read_and_transform_img(false_pred[i])\n",
    "basename = os.path.basename(false_pred[i])\n",
    "preds = model1.predict(images)\n",
    "prediction = np.argmax(preds)\n",
    "pct = np.max(preds)\n",
    "\n",
    "if prediction == 0:\n",
    "    print('It\\'s no aesthethic!')\n",
    "elif prediction == 1:\n",
    "    print('It\\'s an aesthethic!')\n",
    "\n",
    "print(pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b39445",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(images[0].astype('double'), model1.predict,  \n",
    "                                     top_labels=2, hide_color=0, num_samples=1000)\n",
    "\n",
    "temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "\n",
    "img1 = mark_boundaries(temp_1, mask_1)\n",
    "img2 = mark_boundaries(temp_2, mask_2)\n",
    "# cv2.imwrite(f'{root_path}/Data/AesthAI/benchmark/images/explainations/{basename}_1', img1, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "# cv2.imwrite(f'{root_path}/Data/AesthAI/benchmark/images/explainations/{basename}_2', img2, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "\n",
    "# img1.save( f'{root_path}/Data/AesthAI/benchmark/images/explainations/{basename}_1', quality=100)\n",
    "# img2.save( f'{root_path}/Data/AesthAI/benchmark/images/explainations/{basename}_2', quality=100)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
